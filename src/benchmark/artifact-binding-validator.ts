/**
 * Artifact-Binding Validation System
 * 
 * Implements TODO.md requirement: "Bind prose to artifacts (stop drift)"
 * Ensures all printed percentages and claims in papers/reports are directly 
 * derived from parquet artifacts with <0.1pp tolerance.
 */

import { promises as fs } from 'fs';
import path from 'path';
import type { BenchmarkRun, ConfigFingerprint } from '../types/benchmark.js';
import type { LensConfig } from '../types/config.js';

// Hero metrics that must be artifact-bound (from TODO.md)
export interface HeroMetrics {
  ur_ndcg10_delta: number;           // Î”nDCG@10 = 21.3% (Â±4.2%)
  ur_ndcg10_ci: number;              // CI for nDCG delta
  ur_recall50_sla_delta_pp: number;  // +18 pp SLA-Recall@50  
  ops_p95: number;                   // p95 = 87 ms
  ops_p99: number;                   // p99 latency
  ops_qps150x: number;               // 11.5Ã— QPS@150ms
  ops_timeouts_delta_pp: number;     // timeouts âˆ’5 pp
  span_coverage: number;             // 100% span coverage
}

// Operations and robustness metrics (elevated to hero)
export interface OpsMetrics {
  p95: number;
  p99: number;
  qps_at_150ms: number;
  qps_multiplier: number;        // QPS multiplier at 150ms
  timeout_reduction_pp: number;  // Timeout reduction in percentage points
  sla_pass_rate: number;
  timeout_rate: number;
  nzc_rate: number; // Non-zero candidates
  span_coverage: number;
}

// Statistical analysis with proper CI calculations
export interface StatisticalAnalysis {
  paired_bootstrap_ci: {
    n_samples: 1000;
    level: 0.95;
    method: 'stratified';
  };
  permutation_test: {
    method: 'paired';
    correction: 'holm';
    alpha: 0.05;
  };
  wilcoxon_test: {
    method: 'signed-rank';
    correction: 'holm';
  };
}

// Pooled qrels methodology (from TODO.md)
export interface PooledQrelsConfig {
  method: 'union_top50_all_systems';
  systems: string[];
  recall_formula: string; // |top50(system) âˆ© Q| / |Q|
  sla_constraint: {
    max_latency_ms: 150;
    apply_before_intersect: true;
  };
}

export class ArtifactBindingValidator {
  private readonly tolerance_pp = 0.1; // 0.1 percentage point tolerance
  private artifactData: Map<string, any> = new Map();
  
  constructor(
    private readonly parquetPath: string,
    private readonly configFingerprint: ConfigFingerprint
  ) {}

  /**
   * Load and parse parquet data that serves as source of truth
   */
  async loadArtifacts(): Promise<void> {
    try {
      // In production would use actual parquet reader
      const jsonData = await fs.readFile(this.parquetPath, 'utf-8');
      const parsed = JSON.parse(jsonData);
      
      // Store benchmark runs and computed metrics
      if (parsed.run_metadata) {
        this.artifactData.set('run_metadata', parsed.run_metadata);
      }
      
      if (parsed.query_results) {
        this.artifactData.set('query_results', parsed.query_results);
      }
      
      console.log(`ðŸ“Š Loaded artifacts from ${this.parquetPath}`);
    } catch (error) {
      throw new Error(`Failed to load artifacts: ${error}`);
    }
  }

  /**
   * Compute hero metrics from artifacts with pooled qrels methodology
   */
  async computeHeroMetrics(): Promise<HeroMetrics> {
    const runMetadata = this.artifactData.get('run_metadata');
    const queryResults = this.artifactData.get('query_results') || [];
    
    if (!runMetadata) {
      throw new Error('No run metadata found in artifacts');
    }

    // Implement pooled qrels recall calculation
    const pooledQrels = this.computePooledQrels(queryResults);
    const slaRecall = this.computeSLAConstrainedRecall(queryResults, 150); // 150ms SLA
    
    // Calculate nDCG improvement with confidence intervals
    const ndcgDelta = this.computeNDCGDelta(queryResults);
    const ndcgCI = this.computeBootstrapCI(queryResults, 'ndcg_at_10', 1000);
    
    // Extract operational metrics
    const opsMetrics = this.extractOperationalMetrics(runMetadata);
    
    return {
      ur_ndcg10_delta: ndcgDelta.delta,
      ur_ndcg10_ci: ndcgCI.half_width,
      ur_recall50_sla_delta_pp: slaRecall.delta_pp,
      ops_p95: opsMetrics.p95,
      ops_p99: opsMetrics.p99,
      ops_qps150x: opsMetrics.qps_multiplier,
      ops_timeouts_delta_pp: opsMetrics.timeout_reduction_pp,
      span_coverage: 1.0 // TODO: Extract from span audit results
    };
  }

  /**
   * Validate that prose claims match artifacts within tolerance
   */
  validateProseBinding(
    heroMetrics: HeroMetrics, 
    proseClaimsMap: Record<string, number>
  ): ValidationResult {
    const violations: ValidationViolation[] = [];
    
    // Check each hero claim against artifact-derived metrics
    const checks = [
      { key: 'ndcg_delta', artifact: heroMetrics.ur_ndcg10_delta, prose: proseClaimsMap.ndcg_delta },
      { key: 'recall50_sla', artifact: heroMetrics.ur_recall50_sla_delta_pp, prose: proseClaimsMap.recall50_sla },
      { key: 'p95_latency', artifact: heroMetrics.ops_p95, prose: proseClaimsMap.p95_latency },
      { key: 'timeout_reduction', artifact: heroMetrics.ops_timeouts_delta_pp, prose: proseClaimsMap.timeout_reduction }
    ];

    for (const check of checks) {
      if (check.prose !== undefined) {
        const diff = Math.abs(check.artifact - check.prose);
        if (diff > this.tolerance_pp) {
          violations.push({
            metric: check.key,
            artifact_value: check.artifact,
            prose_value: check.prose,
            difference: diff,
            tolerance: this.tolerance_pp
          });
        }
      }
    }

    return {
      passed: violations.length === 0,
      violations,
      artifact_hash: this.configFingerprint.config_hash,
      validation_timestamp: new Date().toISOString()
    };
  }

  /**
   * Validate infrastructure description against actual storage configuration
   */
  validateInfrastructureBinding(paperContent: string, config?: LensConfig): ValidationResult {
    const violations: ValidationViolation[] = [];
    
    // Get storage backend from config (default to memory_mapped_segments)
    const storageBackend = config?.tech_stack.storage || 'memory_mapped_segments';
    
    // Check for PostgreSQL/pgvector mentions when using local shards
    if (storageBackend === 'memory_mapped_segments') {
      const postgresqlMatches = paperContent.match(/PostgreSQL|pgvector/gi);
      const contextualMatches = paperContent.match(/(Optional|variant|multi-tenant|deployment variant).*PostgreSQL|(Optional|variant|multi-tenant|deployment variant).*pgvector|PostgreSQL.*(Optional|variant|multi-tenant|deployment variant)|pgvector.*(Optional|variant|multi-tenant|deployment variant)/gi);
      
      const problematicMatches = (postgresqlMatches?.length || 0) - (contextualMatches?.length || 0);
      if (problematicMatches > 0) {
        violations.push({
          metric: 'infrastructure_storage',
          artifact_value: 0, // memory_mapped_segments
          prose_value: 1, // postgresql/pgvector mentioned
          difference: problematicMatches,
          tolerance: 0
        });
      }
      
      // Ensure local-first terminology is present
      const localShardTerms = [
        'memory-mapped shards',
        'portable.*shard',
        'append-only segments',
        'atomic index swaps',
        'in-process HNSW'
      ];
      
      const hasLocalShardDescription = localShardTerms.some(term => 
        new RegExp(term, 'i').test(paperContent)
      );
      
      if (!hasLocalShardDescription) {
        violations.push({
          metric: 'infrastructure_description',
          artifact_value: 1, // local-first architecture should be described
          prose_value: 0, // missing local-first description
          difference: 1,
          tolerance: 0
        });
      }
    }
    
    // Check for pgvector mentions when that's the configured backend
    if (storageBackend === 'pgvector') {
      const hasPostgresDescription = /PostgreSQL|pgvector/i.test(paperContent);
      if (!hasPostgresDescription) {
        violations.push({
          metric: 'infrastructure_storage',
          artifact_value: 1, // pgvector should be described
          prose_value: 0, // missing pgvector description
          difference: 1,
          tolerance: 0
        });
      }
    }

    return {
      passed: violations.length === 0,
      violations,
      artifact_hash: this.configFingerprint.config_hash,
      validation_timestamp: new Date().toISOString()
    };
  }

  /**
   * Generate artifact-bound hero sentence with template placeholders
   */
  generateHeroSentence(heroMetrics: HeroMetrics): string {
    const template = `UR (NL): **Î”nDCG@10 = <%=pct(${heroMetrics.ur_ndcg10_delta.toFixed(3)})%> (Â±<%=pct(${heroMetrics.ur_ndcg10_ci.toFixed(3)})%>)**, ` +
      `**SLA-Recall@50 = +<%=pp(${heroMetrics.ur_recall50_sla_delta_pp.toFixed(1)})%>**, ` +
      `**p95 = <%=ms(${heroMetrics.ops_p95.toFixed(0)})%>**, ` +
      `**QPS@150 ms = <%=x(${heroMetrics.ops_qps150x.toFixed(1)})%>Ã—**, ` +
      `**Timeouts = âˆ’<%=pp(${heroMetrics.ops_timeouts_delta_pp.toFixed(1)})%>**, ` +
      `**Span = <%=pct(${heroMetrics.span_coverage.toFixed(3)})%>**.`;
    
    return template;
  }

  // Private helper methods

  private computePooledQrels(queryResults: any[]): any {
    // Implementation: Q = â‹ƒ_systems top50(system, UR)
    // For each query, union the top-50 results across all systems
    const pooledRelevanceByQuery = new Map();
    
    // Group results by query and system
    for (const result of queryResults) {
      const queryId = result.query_id;
      if (!pooledRelevanceByQuery.has(queryId)) {
        pooledRelevanceByQuery.set(queryId, new Set());
      }
      
      // Add top-50 results for this system to the pool
      const top50 = result.hits?.slice(0, 50) || [];
      for (const hit of top50) {
        const spanKey = `${hit.file}:${hit.line}:${hit.col}`;
        pooledRelevanceByQuery.get(queryId).add(spanKey);
      }
    }
    
    return pooledRelevanceByQuery;
  }

  private computeSLAConstrainedRecall(queryResults: any[], maxLatencyMs: number): { delta_pp: number } {
    // Filter results to only those meeting SLA before computing recall
    const slaCompliantResults = queryResults.filter(result => 
      result.latency_ms <= maxLatencyMs
    );
    
    // Compute recall on SLA-compliant results only
    let totalRelevant = 0;
    let totalRetrieved = 0;
    
    for (const result of slaCompliantResults) {
      const relevant = result.hits?.filter((hit: any) => hit.relevance_score > 0.5)?.length || 0;
      totalRelevant += relevant;
      totalRetrieved += Math.min(result.hits?.length || 0, 50); // R@50
    }
    
    const recall = totalRetrieved > 0 ? totalRelevant / totalRetrieved : 0;
    
    // Compare against baseline (placeholder - would load baseline data)
    const baselineRecall = 0.667; // From TODO.md example
    const delta_pp = (recall - baselineRecall) * 100; // Convert to percentage points
    
    return { delta_pp };
  }

  private computeNDCGDelta(queryResults: any[]): { delta: number } {
    // Calculate nDCG@10 and compare against baseline
    let totalNDCG = 0;
    let validQueries = 0;
    
    for (const result of queryResults) {
      const ndcg = this.calculateNDCG(result.hits?.slice(0, 10) || [], 10);
      if (!isNaN(ndcg)) {
        totalNDCG += ndcg;
        validQueries++;
      }
    }
    
    const avgNDCG = validQueries > 0 ? totalNDCG / validQueries : 0;
    const baselineNDCG = 0.626; // From TODO.md: 0.626 â†’ 0.779
    const delta = (avgNDCG - baselineNDCG) / baselineNDCG; // Relative improvement
    
    return { delta };
  }

  private computeBootstrapCI(queryResults: any[], metric: string, nSamples: number): { half_width: number } {
    // Stratified bootstrap for confidence intervals
    const values = queryResults.map(r => r.metrics?.[metric] || 0).filter(v => !isNaN(v));
    
    if (values.length === 0) return { half_width: 0 };
    
    // Bootstrap sampling
    const bootstrapMeans: number[] = [];
    for (let i = 0; i < nSamples; i++) {
      const sample = [];
      for (let j = 0; j < values.length; j++) {
        sample.push(values[Math.floor(Math.random() * values.length)]);
      }
      const mean = sample.reduce((a, b) => a + b, 0) / sample.length;
      bootstrapMeans.push(mean);
    }
    
    // Calculate 95% CI
    bootstrapMeans.sort((a, b) => a - b);
    const lower = bootstrapMeans[Math.floor(nSamples * 0.025)];
    const upper = bootstrapMeans[Math.floor(nSamples * 0.975)];
    const half_width = (upper - lower) / 2;
    
    return { half_width };
  }

  private extractOperationalMetrics(runMetadata: any): OpsMetrics {
    const latencies = runMetadata.metrics?.stage_latencies || {};
    
    return {
      p95: latencies.e2e_p95 || 0,
      p99: latencies.e2e_p99 || latencies.e2e_p95 * 1.2, // Estimate if not available
      qps_at_150ms: this.calculateQPSAtLatency(runMetadata, 150),
      qps_multiplier: this.calculateQPSMultiplier(runMetadata, 150),
      timeout_reduction_pp: this.calculateTimeoutReduction(runMetadata),
      sla_pass_rate: this.calculateSLAPassRate(runMetadata, 150),
      timeout_rate: runMetadata.metrics?.timeout_rate || 0,
      nzc_rate: this.calculateNZCRate(runMetadata),
      span_coverage: 1.0 // TODO: Extract from span audit
    };
  }

  private calculateNDCG(hits: any[], k: number): number {
    if (!hits || hits.length === 0) return 0;
    
    // DCG calculation
    let dcg = 0;
    for (let i = 0; i < Math.min(hits.length, k); i++) {
      const relevance = hits[i].relevance_score || 0;
      const position = i + 1;
      dcg += relevance / Math.log2(position + 1);
    }
    
    // IDCG calculation (ideal ranking)
    const idealHits = [...hits].sort((a, b) => (b.relevance_score || 0) - (a.relevance_score || 0));
    let idcg = 0;
    for (let i = 0; i < Math.min(idealHits.length, k); i++) {
      const relevance = idealHits[i].relevance_score || 0;
      const position = i + 1;
      idcg += relevance / Math.log2(position + 1);
    }
    
    return idcg > 0 ? dcg / idcg : 0;
  }

  private calculateQPSAtLatency(runMetadata: any, maxLatencyMs: number): number {
    // Placeholder implementation - would analyze latency distribution
    const avgLatency = runMetadata.metrics?.stage_latencies?.e2e_p50 || 20;
    return Math.max(1000 / maxLatencyMs, 1); // Simple calculation
  }

  private calculateSLAPassRate(runMetadata: any, slaMs: number): number {
    // Percentage of queries meeting SLA
    const p95Latency = runMetadata.metrics?.stage_latencies?.e2e_p95 || 0;
    return p95Latency <= slaMs ? 1.0 : 0.8; // Simplified
  }

  private calculateNZCRate(runMetadata: any): number {
    // Non-zero candidates rate
    const fanOut = runMetadata.metrics?.fan_out_sizes || {};
    const totalCandidates = fanOut.stage_a + fanOut.stage_b + (fanOut.stage_c || 0);
    return totalCandidates > 0 ? 1.0 : 0.0;
  }

  private calculateQPSMultiplier(runMetadata: any, targetLatencyMs: number): number {
    // Calculate QPS multiplier at target latency
    const avgLatency = runMetadata.metrics?.stage_latencies?.e2e_p50 || 20;
    const baselineQPS = 100; // baseline QPS
    const currentQPS = Math.min(1000 / avgLatency, 1000 / targetLatencyMs);
    return currentQPS / baselineQPS;
  }

  private calculateTimeoutReduction(runMetadata: any): number {
    // Calculate timeout reduction in percentage points
    const currentTimeout = runMetadata.metrics?.timeout_rate || 0;
    const baselineTimeout = 0.05; // 5% baseline
    return (baselineTimeout - currentTimeout) * 100; // Convert to percentage points
  }
}

// Types for validation results
export interface ValidationViolation {
  metric: string;
  artifact_value: number;
  prose_value: number;
  difference: number;
  tolerance: number;
}

export interface ValidationResult {
  passed: boolean;
  violations: ValidationViolation[];
  artifact_hash: string;
  validation_timestamp: string;
}

/**
 * Build-time validation function (called by build system)
 */
export async function validateArtifactBinding(
  parquetPath: string,
  configFingerprint: ConfigFingerprint,
  proseClaimsPath: string
): Promise<void> {
  const validator = new ArtifactBindingValidator(parquetPath, configFingerprint);
  await validator.loadArtifacts();
  
  const heroMetrics = await validator.computeHeroMetrics();
  
  // Load prose claims from external file (JSON format)
  const proseClaimsRaw = await fs.readFile(proseClaimsPath, 'utf-8');
  const proseClaims = JSON.parse(proseClaimsRaw);
  
  const validation = validator.validateProseBinding(heroMetrics, proseClaims);
  
  if (!validation.passed) {
    console.error(`ðŸš¨ ARTIFACT BINDING VALIDATION FAILED`);
    const tolerancePp = 0.1; // Use local constant instead of private property
    console.error(`Violations (tolerance: ${tolerancePp}pp):`);
    
    for (const violation of validation.violations) {
      console.error(`  ${violation.metric}: artifact=${violation.artifact_value.toFixed(3)}, prose=${violation.prose_value.toFixed(3)}, diff=${violation.difference.toFixed(3)}pp`);
    }
    
    throw new Error('Build failed due to artifact binding violations');
  }
  
  console.log(`âœ… Artifact binding validation passed`);
  console.log(`Hero sentence: ${validator.generateHeroSentence(heroMetrics)}`);
}