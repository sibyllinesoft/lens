# Protocol v2.2 - Finalized competitor breadth with expanded slices
# Wider coverage: more systems, slices, and languages with CI discipline

embeddings:
  name: parity_gemma256            # Fixed OSS baseline for fair comparison
  query_preproc: normalize_nfc_lower_code
  doc_preproc:   normalize_nfc_lower_code
  cache: embeddings/.cache
  dim: 256

systems:
  # === LEXICAL SLICE ===
  - id: ripgrep
    runner: docker://ghcr.io/burntsushi/ripgrep:latest
    prepare: ["rg","--version"]
    search:  ["rg","--json","--line-number","--column","{QUERY}","{CORPUS_ROOT}"]
    map: {path: "data.path.text", line: "data.line_number", col: "data.submatches[0].start"}
    supports: ["regex","substring","clone_heavy","bloat_noise"]
    slice: "lexical"
    tier: 1

  - id: livegrep
    runner: docker://livegrep:latest
    prepare: ["codesearch","--index","/idx","--repos","repos.yaml"]
    search:  ["refinery","--index","/idx","--json","--timeout_ms","{SLA_MS}","{QUERY}"]
    map: {path: "data.path", line: "data.line_number", col: "data.col_number"}
    supports: ["regex","substring","cross_repo","time_travel"]
    slice: "lexical"
    tier: 1

  - id: zoekt
    runner: docker://zoekt:latest
    prepare: ["zoekt-index","--incremental","--prefix","/idx","--","{CORPUS_ROOT}"]
    search:  ["zoekt","--json","--max_matches","50","--shard_timeout","{SLA_MS}ms","--index_dir","/idx","{QUERY}"]
    map: {path: "data.filename", line: "data.line_number", col: "data.byte_offset"}
    supports: ["regex","substring","symbol","clone_heavy","bloat_noise","cross_repo"]
    slice: "lexical"
    tier: 1
    index_params: {shards: "auto", memory_mb: 2048}

  - id: bm25
    runner: internal
    search: ["bm25_search","--k1","1.2","--b","0.75","--timeout_ms","{SLA_MS}","{QUERY}"]
    supports: ["substring","bloat_noise"]
    slice: "lexical"
    tier: 2

  # === STRUCTURAL SLICE ===
  - id: comby
    runner: docker://comby/comby:latest
    prepare: ["comby","--version"]
    search:  ["comby","-matcher",".ts,.js,.py,.rs,.go","-f","{CORPUS_ROOT}","{QUERY}","","--json-lines","--timeout","{SLA_MS}"]
    map: {path: "data.uri", line: "data.range.start.line", col: "data.range.start.column"}
    supports: ["structural","clone_heavy","cross_repo"]
    slice: "structural"
    tier: 1
    index_params: {cache_size_mb: 512}

  - id: ast_grep
    runner: docker://ast-grep/ast-grep:latest
    prepare: ["ast-grep","--version"]
    search:  ["ast-grep","--json","--lang","typescript,python,rust,go","--timeout","{SLA_MS}","{QUERY}","{CORPUS_ROOT}"]
    map: {path: "data.path", line: "data.start_line", col: "data.start_col"}
    supports: ["structural","symbol","cross_repo"]
    slice: "structural" 
    tier: 1
    index_params: {tree_sitter_cache: "/tmp/ts_cache"}

  # === HYBRID SLICE ===
  - id: opensearch_knn
    runner: docker://opensearchproject/opensearch:2.11.1
    prepare: ["curl","-X","PUT","localhost:9200/code_index","--data-binary","@mapping.json"]
    search:  ["curl","-X","POST","localhost:9200/code_index/_search","--data-binary","@query.json","--timeout","{SLA_MS}ms"]
    map: {path: "hits.hits[].source.path", line: "hits.hits[].source.line", col: "hits.hits[].source.col", score: "hits.hits[]._score"}
    supports: ["substring","symbol","nl_to_span","filter_heavy","clone_heavy","bloat_noise"]
    slice: "hybrid"
    tier: 1
    embeddings: "parity_gemma256"
    index_params: {shards: 1, replicas: 0, knn_algo: "hnsw", ef_construction: 512, m: 16}

  - id: vespa_hnsw  
    runner: docker://vespaengine/vespa:8.261.17
    prepare: ["vespa-deploy","prepare","code-search-app"]
    search:  ["curl","-X","POST","http://localhost:8080/search/","--data","{\"yql\":\"select * from code where {}\",\"timeout\":\"{SLA_MS}ms\"}"]
    map: {path: "root.children[].fields.path", line: "root.children[].fields.line", col: "root.children[].fields.col"}
    supports: ["substring","symbol","nl_to_span","filter_heavy","cross_repo","time_travel"]
    slice: "hybrid"
    tier: 1
    embeddings: "parity_gemma256"
    index_params: {hnsw_max_connections: 16, hnsw_ef_construction: 200, hnsw_ef_search: 100}

  - id: qdrant_hybrid
    runner: docker://qdrant/qdrant:v1.7.4
    prepare: ["curl","-X","PUT","localhost:6333/collections/code","--data-binary","@collection.json"]
    search:  ["curl","-X","POST","localhost:6333/collections/code/points/search","--data-binary","@hybrid_query.json","--timeout","{SLA_MS}ms"]
    map: {path: "result.points[].payload.path", line: "result.points[].payload.line", col: "result.points[].payload.col", score: "result.points[].score"}
    supports: ["substring","symbol","nl_to_span","filter_heavy","clone_heavy","bloat_noise"]
    slice: "hybrid"
    tier: 1
    embeddings: "parity_gemma256"
    index_params: {vector_size: 256, distance: "cosine", hnsw_ef: 128, hnsw_m: 16, quantization: "scalar"}

  # === PURE ANN SLICE ===
  - id: faiss_ivf_pq
    runner: docker://pytorch/pytorch:2.1.2-cuda11.8-cudnn8-runtime
    prepare: ["python","-c","import faiss; print(faiss.__version__)"]
    search:  ["python","faiss_search.py","--index","code.index","--nprobe","32","--timeout_ms","{SLA_MS}","{QUERY_VECTOR}"]
    map: {path: "data.path", line: "data.line", col: "data.col", score: "data.distance"}
    supports: ["nl_to_span","filter_heavy","clone_heavy"]
    slice: "pure_ann"
    tier: 1
    embeddings: "parity_gemma256"
    index_params: {nlist: 4096, m: 8, nbits: 8, nprobe: 32}

  - id: scann
    runner: docker://tensorflow/tensorflow:2.14.0
    prepare: ["python","-c","import scann; print(scann.__version__)"]
    search:  ["python","scann_search.py","--searcher","code.searcher","--num_neighbors","50","--leaves_to_search","100","--timeout_ms","{SLA_MS}","{QUERY_VECTOR}"]  
    map: {path: "data.path", line: "data.line", col: "data.col", score: "data.distance"}
    supports: ["nl_to_span","filter_heavy"]
    slice: "pure_ann"
    tier: 1
    embeddings: "parity_gemma256" 
    index_params: {num_leaves: 2000, num_leaves_to_search: 100, dimensions_per_block: 2, anisotropic_quantization_threshold: 0.2}

  # === MULTI-SIGNAL SLICE ===
  - id: lens
    runner: internal
    search: ["lens","search","--sla_ms","{SLA_MS}","--format","json","{QUERY}"]
    map: {path: "data.path", line: "data.line", col: "data.col", score: "data.score"}
    supports: ["regex","substring","structural","symbol","nl_to_span","filter_heavy","clone_heavy","bloat_noise","cross_repo","time_travel"]
    slice: "multi_signal" 
    tier: 1
    embeddings: "parity_gemma256"
    index_params: {lex_weight: 0.4, struct_weight: 0.3, sem_weight: 0.3, fusion: "rrf_k60"}

# Slice definitions with expanded coverage
slices:
  lexical:
    description: "Pure lexical matching - regex, substring, statistical ranking"
    includes: ["regex", "substring", "clone_heavy", "bloat_noise"]
  structural:  
    description: "AST-aware and structural pattern matching"
    includes: ["structural", "symbol"]
  hybrid:
    description: "Sparse + dense vector fusion for semantic understanding"
    includes: ["substring", "symbol", "nl_to_span", "filter_heavy"]
  pure_ann:
    description: "Dense vector similarity search only"  
    includes: ["nl_to_span", "filter_heavy"]
  multi_signal:
    description: "Lens - combines lexical, structural, and semantic signals"
    includes: ["*"]  # All scenarios

# Language tiers for coverage gates
language_tiers:
  tier_1: ["typescript", "python", "rust"]
  tier_2: ["go", "java", "javascript"]
  tier_3: ["cpp", "csharp", "php"]

# Power and reliability gates
gates:
  min_queries_per_suite: 800
  max_ci_width_ndcg10: 0.03
  max_slice_ece: 0.02
  max_p99_over_p95: 2.0
  min_ndcg_variance: 1e-4
  min_pool_contribution: 0.30
  max_jaccard_similarity: 0.8

# Expanded scenarios for slice coverage
scenarios:
  # Core scenarios (from v2.1)
  regex:
    systems: ["ripgrep", "livegrep", "zoekt", "lens"]
    description: "Regular expression queries"
    
  substring: 
    systems: ["ripgrep", "livegrep", "zoekt", "opensearch_knn", "vespa_hnsw", "qdrant_hybrid", "bm25", "lens"]
    description: "Simple substring matching"
    
  structural:
    systems: ["comby", "ast_grep", "lens"] 
    description: "AST pattern matching"
    
  symbol:
    systems: ["zoekt", "ast_grep", "opensearch_knn", "vespa_hnsw", "qdrant_hybrid", "lens"]
    description: "Symbol and identifier search"
    
  nl_to_span:
    systems: ["opensearch_knn", "vespa_hnsw", "qdrant_hybrid", "faiss_ivf_pq", "scann", "lens"]
    description: "Natural language to code span retrieval"
    
  filter_heavy:
    systems: ["vespa_hnsw", "qdrant_hybrid", "opensearch_knn", "faiss_ivf_pq", "scann", "lens"]
    description: "Complex filtering and faceted search"

  # New scenarios (v2.2 expansion)  
  clone_heavy:
    systems: ["ripgrep", "livegrep", "zoekt", "comby", "opensearch_knn", "qdrant_hybrid", "faiss_ivf_pq", "lens"]
    description: "Search in codebases with high duplication"
    
  bloat_noise:
    systems: ["ripgrep", "zoekt", "opensearch_knn", "qdrant_hybrid", "bm25", "lens"]
    description: "Search with noisy/bloated codebases (generated files, minified code)"
    
  cross_repo:
    systems: ["livegrep", "zoekt", "comby", "ast_grep", "vespa_hnsw", "lens"]
    description: "Cross-repository code search"
    
  time_travel:
    systems: ["livegrep", "vespa_hnsw", "lens"]
    description: "Historical/versioned code search"

# Remedy classes for gap analysis
remedy_classes:
  needs_struct_seeds: "Requires better AST/structural pattern extraction"
  ann_hygiene: "Vector index quality or embedding issues"
  lsp_recall: "LSP-based symbol extraction problems" 
  clone_expansion: "Needs better handling of duplicated code"
  router_thresholds: "Multi-signal routing threshold tuning"
  lexical_precision: "Lexical matching too broad or narrow"
  timeout_handling: "SLA compliance and timeout management"