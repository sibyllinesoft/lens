#!/usr/bin/env node

/**
 * Benchmark Protocol v1.0 CLI - Complete runbook interface
 * 
 * This implements all commands specified in the protocol:
 * - build-pool: Create pooled qrels from multiple systems
 * - warmup: Prepare systems and validate hardware parity
 * - run: Execute benchmark suites with SLA enforcement
 * - score: Calculate metrics with statistical testing
 * - mine: Automated gap mining and weakness analysis
 * - plot: Generate publication-grade visualizations
 */

import { program } from 'commander';
import { promises as fs } from 'fs';
import * as path from 'path';
import { PooledQrelsBuilder, PooledQrelsConfig, createQrelsBuilder } from './pooled-qrels-builder';
import { AdapterRegistry, createAdapter, AdapterConfig } from './competitor-adapters';
import { SLAExecutionEngine, BatchExecutor, BenchmarkQuery } from './sla-execution-engine';
import { MetricsCalculator, AggregateMetrics } from './metrics-calculator';
import { ParquetExporter } from './parquet-exporter';

interface CLIConfig {
  suites: string[];
  systems: string[];
  sla: number;
  output: string;
  bootstrap?: number;
  permute?: boolean;
  holm?: boolean;
}

/**
 * Build pooled qrels from multiple systems
 */
async function buildPool(options: any): Promise<void> {
  console.log('üèóÔ∏è  Building pooled qrels...');
  console.log(`üìã Suites: ${options.suites}`);
  console.log(`üîß Systems: ${options.systems}`);
  console.log(`‚è±Ô∏è  SLA: ${options.sla}ms`);

  const config: PooledQrelsConfig = {
    suites: options.suites.split(','),
    systems: options.systems.split(','),
    sla_ms: parseInt(options.sla),
    top_k: options.topK || 50,
    min_agreement: options.minAgreement || 2,
    output_dir: options.out
  };

  // Ensure output directory exists
  await fs.mkdir(config.output_dir, { recursive: true });

  try {
    for (const suite of config.suites) {
      const builder = createQrelsBuilder(suite, config);
      await builder.buildPooledQrels();
    }

    console.log('‚úÖ Pooled qrels building complete');
    console.log(`üìÅ Output: ${config.output_dir}`);
    
  } catch (error) {
    console.error('‚ùå Pooled qrels building failed:', error.message);
    process.exit(1);
  }
}

/**
 * Warmup systems and validate hardware parity
 */
async function warmup(options: any): Promise<void> {
  console.log('üî• Warming up systems...');
  console.log(`üîß Systems: ${options.systems}`);
  console.log(`üîí Hardware check: ${options.hardwareCheck}`);

  const systems = options.systems.split(',');
  const registry = new AdapterRegistry();

  // Initialize SLA engine with hardware validation
  const engine = new SLAExecutionEngine({
    sla_ms: 150,
    hardware_validation: options.hardwareCheck === 'strict',
    resource_monitoring: true
  });

  await engine.initialize();

  // Validate system requirements
  const requirements = await engine.validateSystemRequirements();
  if (!requirements.valid) {
    console.error('‚ùå System requirements not met');
    requirements.warnings.forEach(warning => console.warn(`‚ö†Ô∏è  ${warning}`));
    process.exit(1);
  }

  if (requirements.warnings.length > 0) {
    console.warn('‚ö†Ô∏è  System warnings:');
    requirements.warnings.forEach(warning => console.warn(`   ${warning}`));
  }

  try {
    // Register and warmup all systems
    for (const systemId of systems) {
      const config: AdapterConfig = {
        system_id: systemId,
        corpus_path: './corpus',
        server_port: systemId === 'lens' ? 3000 : undefined,
        warmup_queries: 10
      };

      console.log(`üöÄ Preparing ${systemId}...`);
      await registry.registerAdapter(systemId, config);
      console.log(`‚úÖ ${systemId} ready`);
    }

    // Collect attestation data
    const attestation = {
      timestamp: new Date().toISOString(),
      hardware_fingerprint: await engine['hardwareAttestation'].collectFingerprint(),
      hardware_info: await engine['hardwareAttestation'].getHardwareInfo(),
      systems: [],
      requirements_check: requirements
    };

    // Collect system information
    for (const systemId of systems) {
      const adapter = registry.getAdapter(systemId);
      if (adapter) {
        const systemInfo = await adapter.getSystemInfo();
        attestation.systems.push(systemInfo);
      }
    }

    // Write attestation file
    const attestationPath = options.attest || 'attestation.json';
    await fs.writeFile(attestationPath, JSON.stringify(attestation, null, 2));

    console.log('‚úÖ Warmup complete');
    console.log(`üîí Attestation written to: ${attestationPath}`);

    // Cleanup
    await registry.teardownAll();

  } catch (error) {
    console.error('‚ùå Warmup failed:', error.message);
    await registry.teardownAll();
    process.exit(1);
  }
}

/**
 * Execute benchmark suite with SLA enforcement
 */
async function run(options: any): Promise<void> {
  console.log('üöÄ Running benchmark suite...');
  console.log(`üìã Suite: ${options.suite}`);
  console.log(`üîß Systems: ${options.systems}`);
  console.log(`‚è±Ô∏è  SLA: ${options.sla}ms`);

  const systems = options.systems.split(',');
  const registry = new AdapterRegistry();

  // Initialize SLA engine
  const engine = new SLAExecutionEngine({
    sla_ms: parseInt(options.sla),
    hardware_validation: true,
    resource_monitoring: true,
    timeout_retries: 1
  });

  await engine.initialize();

  try {
    // Register all systems
    for (const systemId of systems) {
      const config: AdapterConfig = {
        system_id: systemId,
        corpus_path: './corpus',
        server_port: systemId === 'lens' ? 3000 : undefined
      };

      await registry.registerAdapter(systemId, config);
    }

    // Load benchmark queries
    const queries = await loadBenchmarkQueries(options.suite);
    console.log(`üìä Loaded ${queries.length} queries for ${options.suite}`);

    // Execute benchmark
    const executor = new BatchExecutor(engine, new Map([...systems.map(s => [s, registry.getAdapter(s)!])]));
    const results = await executor.executeBatch(queries);

    // Ensure output directory exists
    await fs.mkdir(options.out, { recursive: true });

    // Write results
    const resultsPath = path.join(options.out, `${options.suite}_results.json`);
    await fs.writeFile(resultsPath, JSON.stringify(results, null, 2));

    // Write execution statistics
    const stats = engine.getExecutionStats();
    const statsPath = path.join(options.out, `${options.suite}_stats.json`);
    await fs.writeFile(statsPath, JSON.stringify(stats, null, 2));

    console.log('‚úÖ Benchmark execution complete');
    console.log(`üìä Results: ${resultsPath}`);
    console.log(`üìà Statistics: ${statsPath}`);
    console.log(`   SLA compliance: ${(stats.sla_compliance_rate * 100).toFixed(1)}%`);
    console.log(`   Error rate: ${(stats.error_rate * 100).toFixed(1)}%`);

    await registry.teardownAll();

  } catch (error) {
    console.error('‚ùå Benchmark execution failed:', error.message);
    await registry.teardownAll();
    process.exit(1);
  }
}

/**
 * Score results with pooled qrels and statistical testing
 */
async function score(options: any): Promise<void> {
  console.log('üßÆ Scoring benchmark results...');
  console.log(`üìÅ Runs: ${options.runs}`);
  console.log(`üéØ Pool: ${options.pool}`);
  console.log(`üî¨ Bootstrap: ${options.bootstrap || 'disabled'}`);

  try {
    // Load pooled qrels
    const qrelsPath = path.join(options.pool, 'pooled_qrels.json');
    const qrelsData = JSON.parse(await fs.readFile(qrelsPath, 'utf8'));
    
    // Load execution results from all runs
    const allResults = [];
    const runFiles = await fs.readdir(options.runs);
    
    for (const file of runFiles) {
      if (file.endsWith('_results.json')) {
        const filePath = path.join(options.runs, file);
        const results = JSON.parse(await fs.readFile(filePath, 'utf8'));
        allResults.push(...results);
      }
    }

    console.log(`üìä Loaded ${allResults.length} execution results`);

    // Calculate comprehensive metrics
    const calculator = new MetricsCalculator();
    calculator.loadQrels(qrelsData);
    
    const metrics = calculator.calculateMetrics(allResults);
    console.log(`üìà Calculated metrics for ${metrics.length} query-system pairs`);

    // Statistical testing (if requested)
    if (options.bootstrap) {
      console.log(`üî¨ Running bootstrap testing with ${options.bootstrap} iterations...`);
      const statResults = await runStatisticalTests(metrics, parseInt(options.bootstrap), options.permute, options.holm);
      
      const statPath = path.join(options.out, 'statistical_tests.json');
      await fs.writeFile(statPath, JSON.stringify(statResults, null, 2));
      console.log(`üìä Statistical test results: ${statPath}`);
    }

    // Export to Parquet format
    const exporter = new ParquetExporter(options.out);
    await exporter.exportAggregateMetrics(metrics);
    await exporter.exportDetailResults(allResults);
    await exporter.exportCSV(metrics, allResults);

    console.log('‚úÖ Scoring complete');
    console.log(`üìÅ Output directory: ${options.out}`);

  } catch (error) {
    console.error('‚ùå Scoring failed:', error.message);
    process.exit(1);
  }
}

/**
 * Mine gaps and weaknesses from scored results
 */
async function mine(options: any): Promise<void> {
  console.log('‚õèÔ∏è  Mining gaps and weaknesses...');
  console.log(`üìä Input: ${options.in}`);

  try {
    // Load aggregate data
    const aggPath = options.in.endsWith('.json') ? options.in : path.join(options.in, 'benchmark_agg.json');
    const aggData = JSON.parse(await fs.readFile(aggPath, 'utf8'));

    const gapResults = await analyzeGaps(aggData);

    // Generate backlog CSV
    const csvOutput = generateBacklogCSV(gapResults);
    
    const outputPath = options.out || 'gaps.csv';
    await fs.writeFile(outputPath, csvOutput);

    console.log('‚úÖ Gap mining complete');
    console.log(`üìä Gaps analysis: ${outputPath}`);
    console.log(`üéØ Found ${gapResults.sliceGaps.length} slice gaps`);
    console.log(`‚ö†Ô∏è  Found ${gapResults.calibrationRisks.length} calibration risks`);

  } catch (error) {
    console.error('‚ùå Gap mining failed:', error.message);
    process.exit(1);
  }
}

/**
 * Generate publication-grade plots
 */
async function plot(options: any): Promise<void> {
  console.log('üìä Generating publication plots...');
  console.log(`üìÅ Input: ${options.in}`);
  console.log(`üñºÔ∏è  Figures: ${options.figures || 'all'}`);

  try {
    // Load scored data
    const aggPath = path.join(options.in, 'benchmark_agg.json');
    const aggData = JSON.parse(await fs.readFile(aggPath, 'utf8'));

    await fs.mkdir(options.out, { recursive: true });

    const figures = options.figures ? options.figures.split(',') : ['hero', 'latency', 'calibration', 'gaps', 'witness', 'utility'];

    for (const figure of figures) {
      console.log(`üìä Generating ${figure} plots...`);
      await generatePlot(figure, aggData, options.out);
    }

    // Generate plot manifest
    const manifest = {
      timestamp: new Date().toISOString(),
      figures: figures,
      data_source: options.in,
      output_directory: options.out,
      format: options.format || 'png',
      dpi: options.dpi || 300
    };

    const manifestPath = path.join(options.out, 'plot_manifest.json');
    await fs.writeFile(manifestPath, JSON.stringify(manifest, null, 2));

    console.log('‚úÖ Plot generation complete');
    console.log(`üìÅ Output directory: ${options.out}`);
    console.log(`üìã Manifest: ${manifestPath}`);

  } catch (error) {
    console.error('‚ùå Plot generation failed:', error.message);
    process.exit(1);
  }
}

/**
 * Package complete reproducibility bundle
 */
async function packageCmd(options: any): Promise<void> {
  console.log('üì¶ Packaging reproducibility bundle...');

  try {
    const packageData = {
      timestamp: new Date().toISOString(),
      run_data: options.runData,
      attestation: options.attestation,
      figures: options.figures,
      protocol_version: '1.0',
      git_hash: await getCurrentGitHash()
    };

    const packagePath = options.out || `benchmark_package_${new Date().toISOString().split('T')[0]}.json`;
    await fs.writeFile(packagePath, JSON.stringify(packageData, null, 2));

    console.log('‚úÖ Package created successfully');
    console.log(`üì¶ Package: ${packagePath}`);

  } catch (error) {
    console.error('‚ùå Packaging failed:', error.message);
    process.exit(1);
  }
}

/**
 * Helper functions
 */
async function loadBenchmarkQueries(suite: string): Promise<BenchmarkQuery[]> {
  const suitePaths = {
    coir: './benchmark-corpus/coir_queries.json',
    swe_verified: './benchmark-corpus/swe_verified_queries.json',
    csn: './benchmark-corpus/csn_queries.json',
    cosqa: './benchmark-corpus/cosqa_queries.json',
    cp_regex: './benchmark-corpus/cp_regex_queries.json'
  };

  const suitePath = suitePaths[suite];
  if (!suitePath) {
    throw new Error(`Unknown suite: ${suite}`);
  }

  const data = JSON.parse(await fs.readFile(suitePath, 'utf8'));
  return data.map((q: any) => ({
    query_id: q.id,
    query_text: q.query,
    suite: suite,
    intent: q.intent || 'semantic',
    language: q.language || 'unknown',
    expected_file: q.expected_file
  }));
}

async function runStatisticalTests(metrics: AggregateMetrics[], bootstrap: number, permute: boolean, holm: boolean): Promise<any> {
  // Statistical testing implementation would go here
  // For now, return placeholder
  console.log(`üî¨ Statistical testing: bootstrap=${bootstrap}, permute=${permute}, holm=${holm}`);
  
  return {
    bootstrap_iterations: bootstrap,
    permutation_test: permute,
    holm_correction: holm,
    timestamp: new Date().toISOString(),
    note: 'Statistical testing implementation pending'
  };
}

async function analyzeGaps(aggData: any[]): Promise<any> {
  // Gap analysis implementation
  console.log(`‚õèÔ∏è  Analyzing gaps in ${aggData.length} results`);
  
  const sliceGaps = aggData
    .filter(d => d.ndcg_at_10 < 0.5)
    .map(d => ({
      query_id: d.query_id,
      system_id: d.system_id,
      intent: d.slice_intent,
      language: d.slice_lang,
      ndcg_gap: 0.5 - d.ndcg_at_10,
      timeout_rate: d.timeout_pct / 100
    }))
    .sort((a, b) => b.ndcg_gap - a.ndcg_gap)
    .slice(0, 20);

  const calibrationRisks = aggData
    .filter(d => d.ece > 0.02)
    .map(d => ({
      query_id: d.query_id,
      system_id: d.system_id,
      ece: d.ece,
      calibration_slope: d.calib_slope
    }));

  return { sliceGaps, calibrationRisks };
}

function generateBacklogCSV(gapResults: any): string {
  const headers = ['slice', 'delta_ndcg_pp', 'timeout_share', 'ece', 'priority', 'effort_estimate'];
  
  const rows = gapResults.sliceGaps.map((gap: any) => [
    `${gap.language}_${gap.intent}`,
    gap.ndcg_gap.toFixed(3),
    gap.timeout_rate.toFixed(3),
    '0.000', // Would need ECE data
    gap.ndcg_gap > 0.2 ? 'high' : 'medium',
    gap.ndcg_gap > 0.2 ? '2_weeks' : '1_week'
  ]);

  return [headers.join(','), ...rows.map(row => row.join(','))].join('\n');
}

async function generatePlot(figure: string, data: any[], outputDir: string): Promise<void> {
  // Plot generation would use a charting library like D3.js or Python matplotlib
  // For now, create placeholder files
  const plotFile = path.join(outputDir, `${figure}_plot.png`);
  const plotData = {
    figure_type: figure,
    data_points: data.length,
    timestamp: new Date().toISOString(),
    note: 'Plot generation implementation pending'
  };

  await fs.writeFile(plotFile.replace('.png', '.json'), JSON.stringify(plotData, null, 2));
  console.log(`üìä ${figure} plot data prepared: ${plotFile.replace('.png', '.json')}`);
}

async function getCurrentGitHash(): Promise<string> {
  try {
    const { exec } = require('child_process');
    return new Promise((resolve, reject) => {
      exec('git rev-parse HEAD', (error: any, stdout: string) => {
        if (error) resolve('unknown');
        else resolve(stdout.trim().substring(0, 8));
      });
    });
  } catch {
    return 'unknown';
  }
}

/**
 * CLI setup
 */
program
  .name('bench')
  .description('Benchmark Protocol v1.0 - Competitive evaluation framework')
  .version('1.0.0');

// Build pooled qrels command
program
  .command('build-pool')
  .description('Build pooled qrels from union of top-k across systems')
  .option('--suites <suites>', 'Comma-separated test suites', 'coir,swe_verified,csn,cosqa')
  .option('--systems <systems>', 'Comma-separated system IDs', 'lens,bm25,bm25_prox,hybrid,sourcegraph')
  .option('--sla <ms>', 'SLA limit in milliseconds', '150')
  .option('--top-k <k>', 'Top-K results to include in pool', '50')
  .option('--min-agreement <n>', 'Minimum system agreement', '2')
  .option('--out <dir>', 'Output directory', 'pool')
  .action(buildPool);

// Warmup command
program
  .command('warmup')
  .description('Warm up systems and validate hardware parity')
  .option('--systems <systems>', 'Comma-separated system IDs', 'lens,bm25,bm25_prox,hybrid,sourcegraph')
  .option('--warmup-queries <n>', 'Number of warmup queries', '10')
  .option('--hardware-check <level>', 'Hardware validation level', 'strict')
  .option('--attest <file>', 'Attestation output file', 'attestation.json')
  .action(warmup);

// Run benchmark command  
program
  .command('run')
  .description('Execute benchmark suite with SLA enforcement')
  .option('--suite <suite>', 'Test suite to run', 'coir')
  .option('--systems <systems>', 'Comma-separated system IDs', 'lens,bm25,bm25_prox,hybrid,sourcegraph')
  .option('--sla <ms>', 'SLA limit in milliseconds', '150')
  .option('--queries-per-system <n>', 'Queries per system', '1000')
  .option('--parallel-workers <n>', 'Parallel workers', '4')
  .option('--out <dir>', 'Output directory', 'runs')
  .action(run);

// Score results command
program
  .command('score')
  .description('Score results with pooled qrels and statistical testing')
  .option('--runs <dir>', 'Directory containing run results', 'runs')
  .option('--pool <dir>', 'Directory containing pooled qrels', 'pool')
  .option('--bootstrap <n>', 'Bootstrap iterations', '2000')
  .option('--permute', 'Enable permutation testing', false)
  .option('--holm', 'Apply Holm correction', false)
  .option('--out <dir>', 'Output directory', 'scored')
  .action(score);

// Mine gaps command
program
  .command('mine')
  .description('Mine gaps and weaknesses from scored results')
  .option('--in <file>', 'Input aggregate parquet/json file', 'scored/agg.parquet')
  .option('--slice-analysis <slices>', 'Analysis dimensions', 'intent,language')
  .option('--witness-attribution', 'Enable witness attribution analysis', false)
  .option('--timeout-analysis', 'Enable timeout attribution analysis', false)  
  .option('--calibration-flags', 'Enable calibration risk flagging', false)
  .option('--out <file>', 'Output gaps CSV file', 'reports/gaps.csv')
  .action(mine);

// Plot generation command
program
  .command('plot')
  .description('Generate publication-grade plots')
  .option('--in <dir>', 'Input scored data directory', 'scored')
  .option('--figures <types>', 'Comma-separated figure types', 'hero,latency,calibration,gaps,witness,utility')
  .option('--format <fmt>', 'Output format', 'png')
  .option('--dpi <n>', 'Resolution DPI', '300')
  .option('--out <dir>', 'Output directory', 'reports/figs')
  .action(plot);

// Package command
program
  .command('package')
  .description('Package complete reproducibility bundle')
  .option('--run-data <dir>', 'Run data directory', 'scored')
  .option('--attestation <file>', 'Attestation file', 'attestation.json')
  .option('--figures <dir>', 'Figures directory', 'reports/figs')
  .option('--out <file>', 'Output package file')
  .action(packageCmd);

// Dashboard command
program
  .command('dashboard')
  .description('Launch interactive dashboard')
  .option('--in <dir>', 'Input scored data directory', 'scored')
  .option('--port <n>', 'Server port', '8080')
  .option('--public-access', 'Allow public access', false)
  .action(async (options) => {
    console.log('üåê Interactive dashboard coming soon...');
    console.log(`üìä Data: ${options.in}`);
    console.log(`üåç Port: ${options.port}`);
  });

// Parse CLI arguments
program.parse();

// Export for testing
export { buildPool, warmup, run, score, mine, plot };